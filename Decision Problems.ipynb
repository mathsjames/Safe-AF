{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Absent_Minded_Driver:\n",
    "    \n",
    "    def __init__(self):   \n",
    "        self.actions = [\"CONT\", \"EXIT\"]\n",
    "        self.states = [\"Intersection_1\", \"Intersection_2\", \"Stop_A\", \"Stop_B\", \"Stop_C\"]\n",
    "        self.end_states = [\"Stop_A\", \"Stop_B\", \"Stop_C\"]\n",
    "        self.epistemic_states = [\"Intersection\", \"Stop_A\", \"Stop_B\", \"Stop_C\"]\n",
    "        \n",
    "        self.state_to_epistemic_state_dict = {\"Intersection_1\":\"Intersection\",\n",
    "                                              \"Intersection_2\":\"Intersection\", \n",
    "                                              \"Stop_A\":\"Stop_A\",\n",
    "                                              \"Stop_B\":\"Stop_B\",\n",
    "                                              \"Stop_C\":\"Stop_C\",\n",
    "                                             }\n",
    "    \n",
    "        self.causation_dict = {(\"Intersection_1\", \"EXIT\"):\"Stop_A\", \n",
    "                               (\"Intersection_1\", \"CONT\"):\"Intersection_2\", \n",
    "                               (\"Intersection_2\", \"EXIT\"):\"Stop_B\",\n",
    "                               (\"Intersection_2\", \"CONT\"):\"Stop_C\",\n",
    "                              }\n",
    "\n",
    "        self.utility_dict = {\"Stop_A\":0,\n",
    "                             \"Stop_B\":4,\n",
    "                             \"Stop_C\":1,\n",
    "                            }\n",
    "\n",
    "    def reset_with(self, agent):\n",
    "        self.finished = False\n",
    "        self.state = \"Intersection_1\"\n",
    "        \n",
    "    def run(self, agent, iterations):\n",
    "        \n",
    "        history = []\n",
    "        \n",
    "        for i in range(iterations):          \n",
    "\n",
    "            self.reset_with(agent)\n",
    "            \n",
    "            while not self.finished:\n",
    "                \n",
    "                epistemic_state = self.epistemic_state()\n",
    "                action_distribution = agent.get_action_distribution(epistemic_state)\n",
    "                action = np.random.choice(self.actions, 1, p=action_distribution)[0]\n",
    "                _, utility = self.do(action)\n",
    "                \n",
    "                history.append((epistemic_state, action, utility))\n",
    "            \n",
    "        return history\n",
    "            \n",
    "    def do(self, action):\n",
    "        \n",
    "        self.state = self.cause(self.state, action)\n",
    "        utility = self.utility(self.state)\n",
    "            \n",
    "        if self.state in self.end_states:\n",
    "            self.finished = True\n",
    "        \n",
    "        return (self.epistemic_state(), utility)\n",
    "        \n",
    "    def utility(self, state):\n",
    "        try:\n",
    "            return self.utility_dict[state]\n",
    "        except:\n",
    "            return 0\n",
    "    \n",
    "    def epistemic_state(self):\n",
    "        return self.state_to_epistemic_state_dict[self.state]\n",
    "        \n",
    "    def cause(self, state, action):\n",
    "        try:\n",
    "            return self.causation_dict[(state, action)]\n",
    "        except:\n",
    "            return state     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Evidential_Blackmail:\n",
    "    \n",
    "    # Full specification of the absent-minded driver problem\n",
    "    \n",
    "    def __init__(self):   \n",
    "        self.actions = [\"PAY\", \"DONT\"]\n",
    "        \n",
    "        self.states = [\"crash+blackmail\", \"no crash+blackmail\", \n",
    "                       \"crash+no blackmail\", \"no crash+no blackmail\",\n",
    "                       \"crash+pay\", \"crash+no pay\", \"no crash+pay\", \"no crash+no pay\"]\n",
    "        \n",
    "        self.end_states = [\"crash+pay\", \"crash+no pay\", \"no crash+pay\", \"no crash+no pay\"]\n",
    "        \n",
    "        self.epistemic_states = [\"Blackmail\", \"No Blackmail\", \"END\"]\n",
    "        \n",
    "        self.state_to_epistemic_state_dict = {\"crash+blackmail\":\"Blackmail\",\n",
    "                                              \"no crash+blackmail\":\"Blackmail\",\n",
    "                                              \"crash+no blackmail\":\"No Blackmail\",\n",
    "                                              \"no crash+no blackmail\":\"No Blackmail\",\n",
    "                                              \"crash+pay\":\"END\",\n",
    "                                              \"crash+no pay\":\"END\",\n",
    "                                              \"no crash+pay\":\"END\",\n",
    "                                              \"no crash+no pay\":\"END\",\n",
    "                                             }\n",
    "    \n",
    "        self.causation_dict = {(\"crash+blackmail\", \"PAY\"):\"crash+pay\", \n",
    "                               (\"crash+blackmail\", \"DONT\"):\"crash+no pay\", \n",
    "                               (\"no crash+blackmail\", \"PAY\"):\"no crash+pay\", \n",
    "                               (\"no crash+blackmail\", \"DONT\"):\"no crash+no pay\", \n",
    "                               (\"crash+no blackmail\", \"PAY\"):\"crash+pay\",\n",
    "                               (\"crash+no blackmail\", \"DONT\"):\"crash+no pay\", \n",
    "                               (\"no crash+no blackmail\", \"PAY\"):\"no crash+pay\", \n",
    "                               (\"no crash+no blackmail\", \"DONT\"):\"no crash+no pay\", \n",
    "                              }\n",
    "\n",
    "        self.utility_dict = {\"no crash+no pay\":11,\n",
    "                             \"no crash+pay\":10,\n",
    "                             \"crash+no pay\":1,\n",
    "                             \"crash+pay\":0\n",
    "                            }\n",
    "\n",
    "    def reset_with(self, agent):\n",
    "        self.finished = False\n",
    "        crash = np.random.choice([True, False], 1, p=[0.5, 0.5])[0]\n",
    "        \n",
    "        if crash:\n",
    "            self.state = \"crash+no blackmail\"\n",
    "            \n",
    "        else:\n",
    "            action_distribution = agent.get_action_distribution(\"Blackmail\")\n",
    "            action = np.random.choice(self.actions, 1, p=action_distribution)[0]\n",
    "            \n",
    "            if action == \"PAY\":\n",
    "                self.state = \"no crash+blackmail\"\n",
    "            else:\n",
    "                self.state = \"no crash+no blackmail\"\n",
    "\n",
    "    def run(self, agent, iterations):\n",
    "        \n",
    "        history = []\n",
    "        \n",
    "        for i in range(iterations):          \n",
    "\n",
    "            self.reset_with(agent)\n",
    "            \n",
    "            while not self.finished:\n",
    "                \n",
    "                epistemic_state = self.epistemic_state()\n",
    "                action_distribution = agent.get_action_distribution(epistemic_state)\n",
    "                action = np.random.choice(self.actions, 1, p=action_distribution)[0]\n",
    "                _, utility = self.do(action)\n",
    "                \n",
    "                history.append((epistemic_state, action, utility))\n",
    "            \n",
    "        return history\n",
    "        \n",
    "    def do(self, action):\n",
    "        \n",
    "        if action in self.actions:\n",
    "            self.state = self.cause(self.state, action)\n",
    "            utility = self.utility(self.state)\n",
    "        else:\n",
    "            assert False\n",
    "            \n",
    "        if self.state in self.end_states:\n",
    "            self.finished = True\n",
    "        \n",
    "        return (self.epistemic_state(), utility)\n",
    "        \n",
    "    def utility(self, state):\n",
    "        try:\n",
    "            return self.utility_dict[state]\n",
    "        except:\n",
    "            return 0\n",
    "    \n",
    "    def epistemic_state(self):\n",
    "        return self.state_to_epistemic_state_dict[self.state]\n",
    "        \n",
    "    def cause(self, state, action):\n",
    "        try:\n",
    "            return self.causation_dict[(state, action)]\n",
    "        except:\n",
    "            return state\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalise(x):\n",
    "    ans = x.copy()\n",
    "    for i in range(len(x)):\n",
    "        ans[i] /= sum(x) \n",
    "    return ans\n",
    "\n",
    "class Softmax:\n",
    "    \n",
    "    def __init__(self, temperature):\n",
    "        self.temperature = float(temperature)\n",
    "        \n",
    "    def function(self, x):\n",
    "        x = [i/self.temperature for i in x]\n",
    "        e_x = np.exp(x - np.max(x))\n",
    "        return e_x / e_x.sum(axis=0)\n",
    "    \n",
    "class Epsilon_Greedy:\n",
    "    \n",
    "    def __init__(self, epsilon):\n",
    "        self.epsilon = float(epsilon)\n",
    "        \n",
    "    def function(self, x):\n",
    "        exploring = np.random.choice([True, False], 1, p=[self.epsilon, 1-self.epsilon])[0]\n",
    "        \n",
    "        if exploring:\n",
    "            return [1.0/len(x) for i in x]\n",
    "        else:\n",
    "            mx = max(x)\n",
    "            mxs = list(filter())\n",
    "            return [1.0/len(mxs) if i==mx else 0 for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Action_Agent:\n",
    "    \n",
    "    # Agent that iterates over actions and selects one that has given it a lot of utility in the past\n",
    "\n",
    "    def __init__(self, exploration_scheme, decision_problem):  \n",
    "\n",
    "        self.actions = decision_problem.actions\n",
    "        self.epistemic_states = decision_problem.epistemic_states\n",
    "        \n",
    "        self.exploration = exploration_scheme\n",
    "        \n",
    "        temp = {action:1 for action in self.actions}\n",
    "        self.expected_utility = {es:temp.copy() for es in self.epistemic_states}\n",
    "        self.times_action_taken = {es:temp.copy() for es in self.epistemic_states}\n",
    "        \n",
    "    def get_action_distribution(self, epistemic_state):\n",
    "        \n",
    "        xp = [self.expected_utility[epistemic_state][action] for action in self.actions]\n",
    "        action_probabilities = self.exploration.function(xp)\n",
    "        return action_probabilities\n",
    "    \n",
    "    def learn_from(self, training_data):\n",
    "        \n",
    "        average_utility = sum([entry[2] for entry in training_data])/len(training_data)\n",
    "        \n",
    "        for epistemic_state, action, utility in training_data:\n",
    "        \n",
    "            i = self.times_action_taken[epistemic_state][action]\n",
    "            exp = self.expected_utility[epistemic_state][action]\n",
    "            self.expected_utility[epistemic_state][action] = (average_utility+exp*i)/(i+1.0)\n",
    "            self.times_action_taken[epistemic_state][action] += 1\n",
    "                \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Naive_Action_Agent:\n",
    "    \n",
    "    # Agent that iterates over actions, but only rewards the action immideately preceding the reward\n",
    "\n",
    "    def __init__(self, exploration_scheme, decision_problem):  \n",
    "\n",
    "        self.actions = decision_problem.actions\n",
    "        self.epistemic_states = decision_problem.epistemic_states\n",
    "        \n",
    "        self.exploration = exploration_scheme\n",
    "        \n",
    "        temp = {action:1 for action in self.actions}\n",
    "        self.expected_utility = {es:temp.copy() for es in self.epistemic_states}\n",
    "        self.times_action_taken = {es:temp.copy() for es in self.epistemic_states}\n",
    "        \n",
    "    def get_action_distribution(self, epistemic_state):\n",
    "        \n",
    "        xp = [self.expected_utility[epistemic_state][action] for action in self.actions]\n",
    "        action_probabilities = self.exploration.function(xp)\n",
    "        return action_probabilities\n",
    "    \n",
    "    def learn_from(self, training_data):\n",
    "        \n",
    "        for epistemic_state, action, utility in training_data:\n",
    "        \n",
    "            i = self.times_action_taken[epistemic_state][action]\n",
    "            exp = self.expected_utility[epistemic_state][action]\n",
    "            self.expected_utility[epistemic_state][action] = (utility+exp*i)/(i+1)\n",
    "            self.times_action_taken[epistemic_state][action] += 1\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Policy_Agent:\n",
    "    \n",
    "    # Agent that iterated over policies\n",
    "\n",
    "    def __init__(self, exploration_scheme, decision_problem):  \n",
    "\n",
    "        self.actions = decision_problem.actions\n",
    "        self.epistemic_states = decision_problem.epistemic_states\n",
    "        \n",
    "        self.exploration = exploration_scheme\n",
    "        \n",
    "        self.policies = [str(x) for x in np.arange(0.0, 1.0, 0.05)] # assumes only two possible actions atm\n",
    "        \n",
    "        temp = {policy:1 for policy in self.policies}\n",
    "        self.expected_utility = {es:temp.copy() for es in self.epistemic_states}\n",
    "        self.times_action_taken = {es:temp.copy() for es in self.epistemic_states}\n",
    "        \n",
    "        self.policy = {es:[1,0] for es in self.epistemic_states}\n",
    "        self.decide_on_policy()\n",
    "        \n",
    "    def get_action_distribution(self, epistemic_state):\n",
    "\n",
    "        return self.policy[epistemic_state]\n",
    "    \n",
    "    def decide_on_policy(self):\n",
    "        \n",
    "        for es in self.epistemic_states:\n",
    "            \n",
    "            xp = [self.expected_utility[es][policy] for policy in self.policies]\n",
    "            policy_probabilities = self.exploration.function(xp)\n",
    "            p = float(np.random.choice(self.policies, 1, p=policy_probabilities)[0])\n",
    "            self.policy[es] = [p, 1-p]\n",
    "            \n",
    "    def learn_from(self, training_data):\n",
    "        \n",
    "        for epistemic_state, policy, utility in training_data:\n",
    "            \n",
    "            policy = str(policy)\n",
    "        \n",
    "            i = self.times_action_taken[epistemic_state][policy]\n",
    "            exp = self.expected_utility[epistemic_state][policy]\n",
    "            self.expected_utility[epistemic_state][policy] = (utility+exp*i)/(i+1)\n",
    "            self.times_action_taken[epistemic_state][policy] += 1\n",
    "                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2474\n",
      "0.500001053042\n",
      "{'CONT': 0.8321567960066389, 'EXIT': 0.8317355792481576}\n",
      "{'CONT': 74943, 'EXIT': 74997}\n",
      "\n",
      "1.24691\n",
      "0.499999161984\n",
      "{'CONT': 0.8316734364944711, 'EXIT': 0.8320086427940054}\n",
      "{'CONT': 74866, 'EXIT': 75034}\n",
      "\n",
      "1.25273\n",
      "0.500000971304\n",
      "{'CONT': 0.834431595445814, 'EXIT': 0.8340430737911079}\n",
      "{'CONT': 75295, 'EXIT': 74872}\n",
      "\n",
      "1.24209\n",
      "0.500001739046\n",
      "{'CONT': 0.8295660178018505, 'EXIT': 0.8288703994723358}\n",
      "{'CONT': 74777, 'EXIT': 75016}\n",
      "\n",
      "1.24756\n",
      "0.500000946895\n",
      "{'CONT': 0.8322367279312615, 'EXIT': 0.831857970011479}\n",
      "{'CONT': 74940, 'EXIT': 75001}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    AMD = Absent_Minded_Driver()\n",
    "    softmax = Softmax(100)\n",
    "    agent = Action_Agent(softmax, AMD)\n",
    "    \n",
    "    total_utility = 0\n",
    "    \n",
    "    for j in range(1000):\n",
    "        history = AMD.run(agent, 100)\n",
    "        agent.learn_from(history)\n",
    "        total_utility += sum([entry[2] for entry in history])\n",
    "\n",
    "    print(total_utility/(1000*100))\n",
    "    # optimal value: 4/3\n",
    "\n",
    "    print(agent.get_action_distribution(\"Intersection\")[0])\n",
    "    # optimal value: 2/3\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.23302\n",
      "0.475532675082\n",
      "{'Intersection': {'CONT': 0.32232106238243985, 'EXIT': 1.3017963761640214}, 'Stop_A': {'CONT': 1, 'EXIT': 1}, 'Stop_B': {'CONT': 1, 'EXIT': 1}, 'Stop_C': {'CONT': 1, 'EXIT': 1}}\n",
      "{'Intersection': {'CONT': 70709, 'EXIT': 77211}, 'Stop_A': {'CONT': 1, 'EXIT': 1}, 'Stop_B': {'CONT': 1, 'EXIT': 1}, 'Stop_C': {'CONT': 1, 'EXIT': 1}}\n",
      "\n",
      "1.22801\n",
      "0.475700451986\n",
      "{'Intersection': {'CONT': 0.3220211268606845, 'EXIT': 1.2947693660150985}, 'Stop_A': {'CONT': 1, 'EXIT': 1}, 'Stop_B': {'CONT': 1, 'EXIT': 1}, 'Stop_C': {'CONT': 1, 'EXIT': 1}}\n",
      "{'Intersection': {'CONT': 70337, 'EXIT': 77352}, 'Stop_A': {'CONT': 1, 'EXIT': 1}, 'Stop_B': {'CONT': 1, 'EXIT': 1}, 'Stop_C': {'CONT': 1, 'EXIT': 1}}\n",
      "\n",
      "1.22773\n",
      "0.47570739576\n",
      "{'Intersection': {'CONT': 0.32175497537226205, 'EXIT': 1.2942248062015622}, 'Stop_A': {'CONT': 1, 'EXIT': 1}, 'Stop_B': {'CONT': 1, 'EXIT': 1}, 'Stop_C': {'CONT': 1, 'EXIT': 1}}\n",
      "{'Intersection': {'CONT': 70246, 'EXIT': 77400}, 'Stop_A': {'CONT': 1, 'EXIT': 1}, 'Stop_B': {'CONT': 1, 'EXIT': 1}, 'Stop_C': {'CONT': 1, 'EXIT': 1}}\n",
      "\n",
      "1.22433\n",
      "0.475830606276\n",
      "{'Intersection': {'CONT': 0.32254208586512556, 'EXIT': 1.2900718940726232}, 'Stop_A': {'CONT': 1, 'EXIT': 1}, 'Stop_B': {'CONT': 1, 'EXIT': 1}, 'Stop_C': {'CONT': 1, 'EXIT': 1}}\n",
      "{'Intersection': {'CONT': 70273, 'EXIT': 77336}, 'Stop_A': {'CONT': 1, 'EXIT': 1}, 'Stop_B': {'CONT': 1, 'EXIT': 1}, 'Stop_C': {'CONT': 1, 'EXIT': 1}}\n",
      "\n",
      "1.23213\n",
      "0.475540665982\n",
      "{'Intersection': {'CONT': 0.3199508515258882, 'EXIT': 1.2991057622925533}, 'Stop_A': {'CONT': 1, 'EXIT': 1}, 'Stop_B': {'CONT': 1, 'EXIT': 1}, 'Stop_C': {'CONT': 1, 'EXIT': 1}}\n",
      "{'Intersection': {'CONT': 69992, 'EXIT': 77608}, 'Stop_A': {'CONT': 1, 'EXIT': 1}, 'Stop_B': {'CONT': 1, 'EXIT': 1}, 'Stop_C': {'CONT': 1, 'EXIT': 1}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    AMD = Absent_Minded_Driver()\n",
    "    softmax = Softmax(100)\n",
    "    agent = Naive_Action_Agent(softmax, AMD)\n",
    "    \n",
    "    total_utility = 0\n",
    "    \n",
    "    for j in range(1000):\n",
    "        history = AMD.run(agent, 100)\n",
    "        agent.learn_from(history)\n",
    "        total_utility += sum([entry[2] for entry in history])\n",
    "\n",
    "    print(total_utility/(1000*100))\n",
    "    # optimal value: 4/3\n",
    "\n",
    "    print(agent.get_action_distribution(\"Intersection\")[0])\n",
    "    # optimal value: 2/3\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95469\n",
      "0.95\n",
      "\n",
      "0.98586\n",
      "0.05\n",
      "\n",
      "0.97213\n",
      "0.7\n",
      "\n",
      "0.99984\n",
      "0.0\n",
      "\n",
      "0.99045\n",
      "0.4\n",
      "\n",
      "0.96792\n",
      "0.65\n",
      "\n",
      "0.97352\n",
      "0.15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    AMD = Absent_Minded_Driver()\n",
    "    softmax = Softmax(100)\n",
    "    agent = Policy_Agent(softmax, AMD)\n",
    "    \n",
    "    total_utility = 0\n",
    "\n",
    "    for j in range(1000):\n",
    "        \n",
    "        agent.decide_on_policy()\n",
    "        history = AMD.run(agent, 100)\n",
    "        policy_history = [(es, agent.policy[es][0], utility) for (es, _, utility) in history]\n",
    "        agent.learn_from(policy_history)\n",
    "        total_utility += sum([entry[2] for entry in history])\n",
    "\n",
    "    print(total_utility/(1000*100))\n",
    "    # optimal value: 4/3\n",
    "\n",
    "    print(agent.get_action_distribution(\"Intersection\")[0])\n",
    "    # optimal value: 2/3\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.49815\n",
      "0.499628970013\n",
      "0.49976818658\n",
      "{'Blackmail': {'PAY': 5.5384274061989505, 'DONT': 5.553268608414139}, 'No Blackmail': {'PAY': 5.47740882407633, 'DONT': 5.486681361547453}, 'END': {'PAY': 1, 'DONT': 1}}\n",
      "{'Blackmail': {'PAY': 12260, 'DONT': 12669}, 'No Blackmail': {'PAY': 37647, 'DONT': 37428}, 'END': {'PAY': 1, 'DONT': 1}}\n",
      "\n",
      "5.51479\n",
      "0.499877012448\n",
      "0.499808345657\n",
      "{'Blackmail': {'PAY': 5.561841262213704, 'DONT': 5.566760764412052}, 'No Blackmail': {'PAY': 5.494114593090252, 'DONT': 5.501780767181714}, 'END': {'PAY': 1, 'DONT': 1}}\n",
      "{'Blackmail': {'PAY': 12486, 'DONT': 12611}, 'No Blackmail': {'PAY': 37367, 'DONT': 37540}, 'END': {'PAY': 1, 'DONT': 1}}\n",
      "\n",
      "5.46644\n",
      "0.499714577781\n",
      "0.49997800393\n",
      "{'Blackmail': {'PAY': 5.503606347170989, 'DONT': 5.515023237179489}, 'No Blackmail': {'PAY': 5.451505564387821, 'DONT': 5.452385407173078}, 'END': {'PAY': 1, 'DONT': 1}}\n",
      "{'Blackmail': {'PAY': 12478, 'DONT': 12480}, 'No Blackmail': {'PAY': 37740, 'DONT': 37306}, 'END': {'PAY': 1, 'DONT': 1}}\n",
      "\n",
      "5.5067\n",
      "0.499751264135\n",
      "0.49971333656\n",
      "{'Blackmail': {'PAY': 5.5469422278965315, 'DONT': 5.556891663310451}, 'No Blackmail': {'PAY': 5.485708655126738, 'DONT': 5.497175193964125}, 'END': {'PAY': 1, 'DONT': 1}}\n",
      "{'Blackmail': {'PAY': 12532, 'DONT': 12415}, 'No Blackmail': {'PAY': 37550, 'DONT': 37507}, 'END': {'PAY': 1, 'DONT': 1}}\n",
      "\n",
      "5.49459\n",
      "0.499944227661\n",
      "0.499795661783\n",
      "{'Blackmail': {'PAY': 5.543787927695302, 'DONT': 5.5460188212776576}, 'No Blackmail': {'PAY': 5.473566554260104, 'DONT': 5.481740083395426}, 'END': {'PAY': 1, 'DONT': 1}}\n",
      "{'Blackmail': {'PAY': 12392, 'DONT': 12539}, 'No Blackmail': {'PAY': 37661, 'DONT': 37412}, 'END': {'PAY': 1, 'DONT': 1}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    EB = Evidential_Blackmail()\n",
    "    softmax = Softmax(100)\n",
    "    agent = Action_Agent(softmax, EB)\n",
    "    \n",
    "    total_utility = 0\n",
    "    \n",
    "    for j in range(1000):\n",
    "        history = EB.run(agent, 100)\n",
    "        agent.learn_from(history)\n",
    "        total_utility += sum([entry[2] for entry in history])\n",
    "\n",
    "    print(total_utility/(1000*100))\n",
    "\n",
    "    print(agent.get_action_distribution(\"Blackmail\")[0])\n",
    "    print(agent.get_action_distribution(\"No Blackmail\")[0])\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.50014\n",
      "0.475020549189\n",
      "0.475255040582\n",
      "{'Blackmail': {'PAY': 9.999191737763812, 'DONT': 10.99920229738355}, 'No Blackmail': {'PAY': 3.4189469606839427, 'DONT': 4.409554615575988}, 'END': {'PAY': 1, 'DONT': 1}}\n",
      "{'Blackmail': {'PAY': 11135, 'DONT': 12536}, 'No Blackmail': {'PAY': 36143, 'DONT': 40190}, 'END': {'PAY': 1, 'DONT': 1}}\n",
      "\n",
      "5.52833\n",
      "0.475020955363\n",
      "0.475483131417\n",
      "{'Blackmail': {'PAY': 9.999206559111357, 'DONT': 10.999200831135633}, 'No Blackmail': {'PAY': 3.448046205714928, 'DONT': 4.429508032630981}, 'END': {'PAY': 1, 'DONT': 1}}\n",
      "{'Blackmail': {'PAY': 11343, 'DONT': 12513}, 'No Blackmail': {'PAY': 36186, 'DONT': 39962}, 'END': {'PAY': 1, 'DONT': 1}}\n",
      "\n",
      "5.52866\n",
      "0.475021000668\n",
      "0.473799154532\n",
      "{'Blackmail': {'PAY': 9.999204525366812, 'DONT': 10.999196980647248}, 'No Blackmail': {'PAY': 3.418584659752651, 'DONT': 4.467579340385851}, 'END': {'PAY': 1, 'DONT': 1}}\n",
      "{'Blackmail': {'PAY': 11314, 'DONT': 12453}, 'No Blackmail': {'PAY': 36062, 'DONT': 40175}, 'END': {'PAY': 1, 'DONT': 1}}\n",
      "\n",
      "5.53139\n",
      "0.47502108057\n",
      "0.47631590597\n",
      "{'Blackmail': {'PAY': 9.999204946996477, 'DONT': 10.99919419822725}, 'No Blackmail': {'PAY': 3.4819860732667287, 'DONT': 4.4300593375228186}, 'END': {'PAY': 1, 'DONT': 1}}\n",
      "{'Blackmail': {'PAY': 11320, 'DONT': 12410}, 'No Blackmail': {'PAY': 36333, 'DONT': 39941}, 'END': {'PAY': 1, 'DONT': 1}}\n",
      "\n",
      "5.50444\n",
      "0.475021178554\n",
      "0.47525716891\n",
      "{'Blackmail': {'PAY': 9.999203187251004, 'DONT': 10.999188509291583}, 'No Blackmail': {'PAY': 3.4347897728833052, 'DONT': 4.425312085657836}, 'END': {'PAY': 1, 'DONT': 1}}\n",
      "{'Blackmail': {'PAY': 11295, 'DONT': 12323}, 'No Blackmail': {'PAY': 36413, 'DONT': 39973}, 'END': {'PAY': 1, 'DONT': 1}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    EB = Evidential_Blackmail()\n",
    "    softmax = Softmax(100)\n",
    "    agent = Naive_Action_Agent(softmax, EB)\n",
    "    \n",
    "    total_utility = 0\n",
    "    \n",
    "    for j in range(1000):\n",
    "        history = EB.run(agent, 100)\n",
    "        agent.learn_from(history)\n",
    "        total_utility += sum([entry[2] for entry in history])\n",
    "\n",
    "    print(total_utility/(1000*100))\n",
    "\n",
    "    print(agent.get_action_distribution(\"Blackmail\")[0])\n",
    "    print(agent.get_action_distribution(\"No Blackmail\")[0])\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.47789\n",
      "0.9\n",
      "0.6\n",
      "{'Blackmail': {'0.0': 1, '0.05': 10.897637795275589, '0.1': 10.868632707774797, '0.15': 10.808290155440414, '0.2': 10.787698412698402, '0.25': 10.736714975845402, '0.3': 10.670774647887319, '0.35': 10.643914473684207, '0.4': 10.584552845528455, '0.45': 10.520263901979254, '0.5': 10.502534395365682, '0.55': 10.457831325301223, '0.6': 10.406579764121657, '0.65': 10.332359813084091, '0.7': 10.306293706293703, '0.75': 10.254098360655743, '0.8': 10.204826368452036, '0.85': 10.138927738927766, '0.9': 10.094454072790292, '0.95': 10.046277665995984}, 'No Blackmail': {'0.0': 4.421113959450017, '0.05': 4.552469135802466, '0.1': 3.928495575221239, '0.15': 3.7887232663642254, '0.2': 4.143349231584539, '0.25': 4.017539810754679, '0.3': 4.314716981132078, '0.35': 4.249879865449303, '0.4': 3.867139334155363, '0.45': 3.88831118813788, '0.5': 3.96816976127321, '0.55': 3.465994962216625, '0.6': 4.054646068711109, '0.65': 3.8957548354684723, '0.7': 3.803612783696155, '0.75': 3.893288763178195, '0.8': 3.733474976392824, '0.85': 3.769946499185858, '0.9': 3.5101857399640504, '0.95': 3.121076233183855}, 'END': {'0.0': 1, '0.05': 1, '0.1': 1, '0.15': 1, '0.2': 1, '0.25': 1, '0.3': 1, '0.35': 1, '0.4': 1, '0.45': 1, '0.5': 1, '0.55': 1, '0.6': 1, '0.65': 1, '0.7': 1, '0.75': 1, '0.8': 1, '0.85': 1, '0.9': 1, '0.95': 1}}\n",
      "{'Blackmail': {'0.0': 1, '0.05': 127, '0.1': 373, '0.15': 193, '0.2': 504, '0.25': 828, '0.3': 568, '0.35': 1216, '0.4': 1230, '0.45': 1061, '0.5': 1381, '0.55': 1411, '0.6': 1611, '0.65': 1712, '0.7': 1430, '0.75': 1586, '0.8': 1699, '0.85': 2145, '0.9': 2308, '0.95': 2485}, 'No Blackmail': {'0.0': 4291, '0.05': 3888, '0.1': 2825, '0.15': 3086, '0.2': 3774, '0.25': 4333, '0.3': 3975, '0.35': 4162, '0.4': 3244, '0.45': 5193, '0.5': 3770, '0.55': 2779, '0.6': 4337, '0.65': 3981, '0.7': 4318, '0.75': 3889, '0.8': 4236, '0.85': 4299, '0.9': 3338, '0.95': 2453}, 'END': {'0.0': 1, '0.05': 1, '0.1': 1, '0.15': 1, '0.2': 1, '0.25': 1, '0.3': 1, '0.35': 1, '0.4': 1, '0.45': 1, '0.5': 1, '0.55': 1, '0.6': 1, '0.65': 1, '0.7': 1, '0.75': 1, '0.8': 1, '0.85': 1, '0.9': 1, '0.95': 1}}\n",
      "\n",
      "5.49113\n",
      "0.35\n",
      "0.0\n",
      "{'Blackmail': {'0.0': 1, '0.05': 10.92896174863388, '0.1': 10.890532544378699, '0.15': 10.829508196721312, '0.2': 10.770220588235292, '0.25': 10.754045307443361, '0.3': 10.711313394018207, '0.35': 10.6268656716418, '0.4': 10.569065343258892, '0.45': 10.515391380826747, '0.5': 10.490344248530652, '0.55': 10.441913439635538, '0.6': 10.395737327188943, '0.65': 10.359821996185634, '0.7': 10.301432664756463, '0.75': 10.251061571125266, '0.8': 10.198863636363637, '0.85': 10.145045045045046, '0.9': 10.084615384615416, '0.95': 10.052902621722835}, 'No Blackmail': {'0.0': 4.39862361037586, '0.05': 4.456739961759072, '0.1': 4.415636677206108, '0.15': 4.085129604365622, '0.2': 3.9495859717486606, '0.25': 4.243571762505832, '0.3': 3.734163508391987, '0.35': 4.019364448857992, '0.4': 3.581618655692731, '0.45': 4.131474978050934, '0.5': 3.697919278014541, '0.55': 4.0585499316005595, '0.6': 3.9258271077908207, '0.65': 3.4472547809993825, '0.7': 3.9096365455151743, '0.75': 3.880259813611974, '0.8': 3.7298808655482625, '0.85': 3.148320131111718, '0.9': 4.029764762361962, '0.95': 3.540540540540542}, 'END': {'0.0': 1, '0.05': 1, '0.1': 1, '0.15': 1, '0.2': 1, '0.25': 1, '0.3': 1, '0.35': 1, '0.4': 1, '0.45': 1, '0.5': 1, '0.55': 1, '0.6': 1, '0.65': 1, '0.7': 1, '0.75': 1, '0.8': 1, '0.85': 1, '0.9': 1, '0.95': 1}}\n",
      "{'Blackmail': {'0.0': 1, '0.05': 183, '0.1': 338, '0.15': 305, '0.2': 544, '0.25': 618, '0.3': 769, '0.35': 737, '0.4': 1209, '0.45': 1137, '0.5': 1191, '0.55': 1317, '0.6': 1736, '0.65': 1573, '0.7': 1745, '0.75': 1884, '0.8': 1936, '0.85': 2220, '0.9': 2730, '0.95': 2136}, 'No Blackmail': {'0.0': 3778, '0.05': 4184, '0.1': 3479, '0.15': 3665, '0.2': 4106, '0.25': 4278, '0.3': 3694, '0.35': 4028, '0.4': 2187, '0.45': 4556, '0.5': 3989, '0.55': 3655, '0.6': 3748, '0.65': 3242, '0.7': 2999, '0.75': 3541, '0.8': 4113, '0.85': 3661, '0.9': 4166, '0.95': 4662}, 'END': {'0.0': 1, '0.05': 1, '0.1': 1, '0.15': 1, '0.2': 1, '0.25': 1, '0.3': 1, '0.35': 1, '0.4': 1, '0.45': 1, '0.5': 1, '0.55': 1, '0.6': 1, '0.65': 1, '0.7': 1, '0.75': 1, '0.8': 1, '0.85': 1, '0.9': 1, '0.95': 1}}\n",
      "\n",
      "5.52852\n",
      "0.45\n",
      "0.35\n",
      "{'Blackmail': {'0.0': 1, '0.05': 10.889610389610388, '0.1': 10.864541832669323, '0.15': 10.830188679245284, '0.2': 10.74606299212598, '0.25': 10.720379146919429, '0.3': 10.698992443324935, '0.35': 10.646572104018913, '0.4': 10.578244274809153, '0.45': 10.549999999999997, '0.5': 10.480465502909395, '0.55': 10.439735099337758, '0.6': 10.35988620199146, '0.65': 10.32941834451903, '0.7': 10.291119691119702, '0.75': 10.24453915823122, '0.8': 10.201750895344208, '0.85': 10.147142278070557, '0.9': 10.094570928196138, '0.95': 10.048243757934832}, 'No Blackmail': {'0.0': 4.704440026507631, '0.05': 4.122866894197951, '0.1': 4.275883256528409, '0.15': 4.219938335046243, '0.2': 4.117063492063475, '0.25': 4.301962893250856, '0.3': 4.263027295285365, '0.35': 4.123818525519836, '0.4': 4.111601766358892, '0.45': 4.234003656307112, '0.5': 4.0090991810737, '0.55': 3.8174752708431474, '0.6': 3.7181615065432485, '0.65': 3.9048246770366406, '0.7': 3.863867684478372, '0.75': 3.641159157799412, '0.8': 3.462283269533886, '0.85': 3.362530413625303, '0.9': 3.3573012353500147, '0.95': 3.513659561693186}, 'END': {'0.0': 1, '0.05': 1, '0.1': 1, '0.15': 1, '0.2': 1, '0.25': 1, '0.3': 1, '0.35': 1, '0.4': 1, '0.45': 1, '0.5': 1, '0.55': 1, '0.6': 1, '0.65': 1, '0.7': 1, '0.75': 1, '0.8': 1, '0.85': 1, '0.9': 1, '0.95': 1}}\n",
      "{'Blackmail': {'0.0': 1, '0.05': 154, '0.1': 251, '0.15': 477, '0.2': 508, '0.25': 633, '0.3': 794, '0.35': 846, '0.4': 1048, '0.45': 1000, '0.5': 1203, '0.55': 1510, '0.6': 1406, '0.65': 1788, '0.7': 1295, '0.75': 1877, '0.8': 2513, '0.85': 2467, '0.9': 2284, '0.95': 2363}, 'No Blackmail': {'0.0': 4527, '0.05': 4688, '0.1': 3255, '0.15': 3892, '0.2': 3528, '0.25': 3719, '0.3': 2821, '0.35': 4232, '0.4': 4982, '0.45': 3829, '0.5': 4396, '0.55': 4246, '0.6': 3133, '0.65': 3793, '0.7': 2358, '0.75': 4417, '0.8': 4441, '0.85': 2877, '0.9': 3157, '0.95': 3331}, 'END': {'0.0': 1, '0.05': 1, '0.1': 1, '0.15': 1, '0.2': 1, '0.25': 1, '0.3': 1, '0.35': 1, '0.4': 1, '0.45': 1, '0.5': 1, '0.55': 1, '0.6': 1, '0.65': 1, '0.7': 1, '0.75': 1, '0.8': 1, '0.85': 1, '0.9': 1, '0.95': 1}}\n",
      "\n",
      "5.4975\n",
      "0.2\n",
      "0.75\n",
      "{'Blackmail': {'0.0': 1, '0.05': 10.891156462585034, '0.1': 10.849829351535837, '0.15': 10.819004524886873, '0.2': 10.744578313253008, '0.25': 10.76481149012568, '0.3': 10.6951871657754, '0.35': 10.645855758880524, '0.4': 10.58780036968577, '0.45': 10.545762711864418, '0.5': 10.505703422053239, '0.55': 10.440113394755494, '0.6': 10.402253521126777, '0.65': 10.34790965881788, '0.7': 10.277210884353766, '0.75': 10.23865698729583, '0.8': 10.1881243063263, '0.85': 10.141787552643892, '0.9': 10.098437500000006, '0.95': 10.040331699962328}, 'No Blackmail': {'0.0': 4.611670020120723, '0.05': 4.435928143712569, '0.1': 4.050088540349093, '0.15': 3.866762520968129, '0.2': 4.254588796185932, '0.25': 4.190781049935986, '0.3': 3.9939812750780206, '0.35': 4.031326480665679, '0.4': 4.186890574214526, '0.45': 3.9723502304147464, '0.5': 4.016417050691263, '0.55': 3.712018906144497, '0.6': 3.4346243826358203, '0.65': 3.9638581432121094, '0.7': 3.7137232845894244, '0.75': 3.3080593849416786, '0.8': 3.4904884318766056, '0.85': 3.7449551569506725, '0.9': 3.5879490150637334, '0.95': 3.556562726613484}, 'END': {'0.0': 1, '0.05': 1, '0.1': 1, '0.15': 1, '0.2': 1, '0.25': 1, '0.3': 1, '0.35': 1, '0.4': 1, '0.45': 1, '0.5': 1, '0.55': 1, '0.6': 1, '0.65': 1, '0.7': 1, '0.75': 1, '0.8': 1, '0.85': 1, '0.9': 1, '0.95': 1}}\n",
      "{'Blackmail': {'0.0': 1, '0.05': 147, '0.1': 293, '0.15': 442, '0.2': 415, '0.25': 557, '0.3': 561, '0.35': 929, '0.4': 1082, '0.45': 1475, '0.5': 1052, '0.55': 1411, '0.6': 1775, '0.65': 2081, '0.7': 1764, '0.75': 2204, '0.8': 1802, '0.85': 2137, '0.9': 1920, '0.95': 2653}, 'No Blackmail': {'0.0': 2982, '0.05': 4175, '0.1': 3953, '0.15': 4173, '0.2': 4195, '0.25': 3124, '0.3': 4486, '0.35': 4086, '0.4': 3692, '0.45': 3906, '0.5': 3472, '0.55': 2962, '0.6': 3847, '0.65': 4427, '0.7': 3556, '0.75': 3772, '0.8': 3890, '0.85': 3568, '0.9': 4315, '0.95': 2758}, 'END': {'0.0': 1, '0.05': 1, '0.1': 1, '0.15': 1, '0.2': 1, '0.25': 1, '0.3': 1, '0.35': 1, '0.4': 1, '0.45': 1, '0.5': 1, '0.55': 1, '0.6': 1, '0.65': 1, '0.7': 1, '0.75': 1, '0.8': 1, '0.85': 1, '0.9': 1, '0.95': 1}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.49777\n",
      "0.45\n",
      "0.55\n",
      "{'Blackmail': {'0.0': 1, '0.05': 10.878504672897199, '0.1': 10.857142857142858, '0.15': 10.822222222222225, '0.2': 10.789473684210524, '0.25': 10.71870794078062, '0.3': 10.705974842767288, '0.35': 10.68490374873354, '0.4': 10.61442307692308, '0.45': 10.519458544839246, '0.5': 10.516366065464247, '0.55': 10.422202001819826, '0.6': 10.400943396226445, '0.65': 10.355214723926348, '0.7': 10.311827956989248, '0.75': 10.242083758937696, '0.8': 10.200379867046525, '0.85': 10.150317892824695, '0.9': 10.09292452830189, '0.95': 10.042544048130653}, 'No Blackmail': {'0.0': 4.3318613380437165, '0.05': 4.569790141532461, '0.1': 4.138209506229808, '0.15': 4.58945610687023, '0.2': 4.24321880650995, '0.25': 4.146871008939978, '0.3': 4.212439588148781, '0.35': 4.20859419464997, '0.4': 3.70177103099304, '0.45': 3.8010989010988996, '0.5': 4.084601769911506, '0.55': 3.7072558373085625, '0.6': 3.7126334519572954, '0.65': 3.8629639966508513, '0.7': 3.85491905354919, '0.75': 3.4321782178217832, '0.8': 3.8712220762155045, '0.85': 3.846787102675507, '0.9': 3.156234598324297, '0.95': 3.327113062568607}, 'END': {'0.0': 1, '0.05': 1, '0.1': 1, '0.15': 1, '0.2': 1, '0.25': 1, '0.3': 1, '0.35': 1, '0.4': 1, '0.45': 1, '0.5': 1, '0.55': 1, '0.6': 1, '0.65': 1, '0.7': 1, '0.75': 1, '0.8': 1, '0.85': 1, '0.9': 1, '0.95': 1}}\n",
      "{'Blackmail': {'0.0': 1, '0.05': 107, '0.1': 287, '0.15': 360, '0.2': 589, '0.25': 743, '0.3': 636, '0.35': 987, '0.4': 1040, '0.45': 1182, '0.5': 1497, '0.55': 1099, '0.6': 1484, '0.65': 1630, '0.7': 1767, '0.75': 1958, '0.8': 2106, '0.85': 2202, '0.9': 2120, '0.95': 2327}, 'No Blackmail': {'0.0': 4529, '0.05': 4098, '0.1': 4334, '0.15': 4192, '0.2': 4424, '0.25': 3132, '0.3': 4759, '0.35': 3514, '0.4': 3162, '0.45': 3640, '0.5': 2825, '0.55': 3983, '0.6': 3372, '0.65': 3583, '0.7': 3212, '0.75': 4040, '0.8': 3044, '0.85': 4373, '0.9': 4058, '0.95': 3644}, 'END': {'0.0': 1, '0.05': 1, '0.1': 1, '0.15': 1, '0.2': 1, '0.25': 1, '0.3': 1, '0.35': 1, '0.4': 1, '0.45': 1, '0.5': 1, '0.55': 1, '0.6': 1, '0.65': 1, '0.7': 1, '0.75': 1, '0.8': 1, '0.85': 1, '0.9': 1, '0.95': 1}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    EB = Evidential_Blackmail()\n",
    "    softmax = Softmax(100)\n",
    "    agent = Policy_Agent(softmax, EB)\n",
    "    \n",
    "    total_utility = 0\n",
    "    \n",
    "    for j in range(1000):\n",
    "        agent.decide_on_policy()\n",
    "        history = EB.run(agent, 100)\n",
    "        policy_history = [(es, agent.policy[es][0], utility) for (es, _, utility) in history]\n",
    "        agent.learn_from(policy_history)\n",
    "        total_utility += sum([entry[2] for entry in history])\n",
    "\n",
    "    print(total_utility/(1000*100))\n",
    "\n",
    "    print(agent.get_action_distribution(\"Blackmail\")[0])\n",
    "    print(agent.get_action_distribution(\"No Blackmail\")[0])\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
